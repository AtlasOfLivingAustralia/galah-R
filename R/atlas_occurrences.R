#' Occurrence records
#'
#' The most common form of data stored by ALA are observations of
#' individual life forms, known as 'occurrences'. This function allows the
#' user to search for occurrence records that match their specific criteria,
#' and return them as a `data.frame` for analysis. Optionally,
#' the user can also request a DOI for a given download to facilitate citation
#' and re-use of specific data resources.
#'
#' @param request optional `data_rquest` object: generated by a call to
#' [galah_call()].
#' @param identify `data.frame`: generated by a call to
#' [galah_identify()].
#' @param filter `data.frame`: generated by a call to
#' [galah_filter()]
#' @param geolocate `string`: generated by a call to
#' [galah_geolocate()]
#' @param select `data.frame`: generated by a call to
#' [galah_select()] 
#' @param mint_doi `logical`: by default no DOI will be generated. Set to
#' `TRUE` if you intend to use the data in a publication or similar
#' @param doi `string`: this argument enables retrieval of occurrence
#' records previously downloaded from the ALA, using the DOI generated by the
#' data.
#' @param refresh_cache `logical`: if set to `TRUE` and 
#' `galah_config(caching = TRUE)` then files cached from a previous query will 
#' be replaced by the current query
#' @details
#' Note that unless care is taken, some queries can be particularly large.
#' While most cases this will simply take a long time to process, if the number
#' of requested records is >50 million the call will not return any data. Users
#' can test whether this threshold will be reached by first calling
#' [atlas_counts()] using the same arguments that they intend to pass to
#' `atlas_occurrences`(). It may also be beneficial when requesting a large
#' number of records to show a progress bar by setting `verbose = TRUE` in
#' [galah_config()].
#' @return An object of class `tbl_df` and `data.frame` (aka a tibble) of 
#' occurrences, containing columns as specified by [galah_select()]. 
#' The `data.frame` object has the following attributes:
#' 
#' * a listing of the user-supplied arguments of the `data_request` 
#' (i.e., identify, filter, geolocate, select)
#' * a `doi` of the data download
#' * the `search_url` of the query to ALA API
#' 
#' @section Examples:
#' ```{r, child = "man/rmd/setup.Rmd"}
#' ```
#' 
#' Search for occurrences matching a taxon identifier
#' 
#' ```{r, comment = "#>", collapse = TRUE, results = "hide", eval = FALSE}
#' galah_config(email = "your-email@email.com")
#' galah_call() |>
#'   galah_identify("Reptilia") |>
#'   atlas_occurrences()
#' ```
#'
#' Search for occurrences in a year range
#' 
#' ```{r, comment = "#>", collapse = TRUE, results = "hide", eval = FALSE}
#' galah_call() |>
#'   galah_filter(year >= 2010, year <= 2020) |>
#'   atlas_occurrences()
#' ```
#'
#' Search for occurrences in a WKT-specified area
#' 
#' ```{r, comment = "#>", collapse = TRUE, results = "hide", eval = FALSE}
#' polygon <- "POLYGON((146.24960 -34.05930,146.37045 -34.05930,146.37045 -34.152549,146.24960 -34.15254,146.24960 -34.05930))"
#' galah_call() |> 
#'   galah_geolocate(polygon) |>
#'   atlas_occurrences()
#' ```
#' 
#' You can also download occurrence records by piping with `%>%` if you prefer.
#' 
#' ```{r, comment = "#>", collapse = TRUE, results = "hide", eval = FALSE}
#' galah_call() %>%
#'   galah_identify("Reptilia") %>%
#'   galah_filter(year >= 2010) %>%
#'   galah_geolocate(polygon) %>%
#'   atlas_occurrences()
#' ```
#' 
#' @export
atlas_occurrences <- function(request = NULL, 
                              identify = NULL, 
                              filter = NULL, 
                              geolocate = NULL,
                              select = galah_select(group = "basic"),
                              mint_doi = FALSE, 
                              doi = NULL, # check missingness code
                              refresh_cache = FALSE
                              ) {
  if(!is.null(request)){
    check_data_request(request)
    current_call <- update_galah_call(request, 
      identify = identify,
      filter = filter,
      geolocate = geolocate,
      select = select,
      mint_doi = mint_doi, # NOTE: check behaviour of update_galah_call here
      doi = doi,
      refresh_cache = refresh_cache
    ) 
          
  }else{
    current_call <- galah_call(
      identify = identify,
      filter = filter,
      geolocate = geolocate,
      select = select,
      mint_doi = mint_doi,
      doi = doi,
      refresh_cache = refresh_cache         
    )
  }

  # subset to available arguments
  custom_call <- current_call[
    names(current_call) %in% names(formals(atlas_occurrences_internal))]
  if(!is.null(doi)){
    custom_call <- custom_call["doi"]
  }
  class(custom_call) <- "data_request"
       
  # check for caching
  caching <- getOption("galah_config")$caching
  cache_file <- cache_filename("occurrences", unlist(custom_call))
  if (caching && file.exists(cache_file) && !refresh_cache) {
    return(read_cache_file(cache_file))
  }
       
  # run function using do.call
  result <- do.call(atlas_occurrences_internal, custom_call)
  attr(result, "data_type") <- "occurrences"
  attr(result, "data_request") <- custom_call

  # if caching requested, save
  if (caching) {
    write_cache_file(object = result, 
                     data_type = "occurrences",
                     cache_file = cache_file)
  }

  result                                
}


# internal workhorse function
atlas_occurrences_internal <- function(identify = NULL,
                                       filter = NULL, 
                                       geolocate = NULL,
                                       select = NULL,
                                       mint_doi = FALSE, 
                                       doi = NULL, 
                                       refresh_cache = FALSE) {

  verbose <- getOption("galah_config")$verbose
  assert_that(is.logical(mint_doi))
  
  # If no filters are specified, reject
  if(
    all(unlist(lapply(list(identify, filter, geolocate, doi), is.null)))
  ){
    bullets <- c(
      "Your data request was too large.",
      i = "A maximum of 50 million records can be retrieved at once.",
      i = "Please narrow the query and try again."
    )
    abort(bullets, call = caller_env())
  }
  
  # search for data using DOI
  if (!missing(doi) && !is.null(doi)) {
    result <- doi_download(doi)
    if(is.null(result)){
      bullets <- c(
        "Calling the API failed for `atlas_occurrences`.",
        i = "This might mean that the ALA system is down. Double check that your query is correct.",
        i = "If you continue to see this message, please email support@ala.org.au."
      )
      inform(bullets)
      return(tibble())
    }else{
      return(result)
    }
  }
  
  profile <- extract_profile(filter)
  query <- build_query(identify, filter, geolocate, select, profile)

  # Check record count
  if (getOption("galah_config")$run_checks) {
    count <- record_count(query)
    if (is.null(count)){
      bullets <- c(
        "Calling the API failed for `atlas_occurrences`.",
        i = "This might mean that the ALA system is down. Double check that your query is correct.",
        i = "If you continue to see this message, please email support@ala.org.au."
      )
      inform(bullets)
      return(tibble())
    }else{
      check_count(count) # aborts under selected circumstances
    }
  }
  
  # Add select default to query when piped
  if(is.null(select)) {
    select <- galah_select(group = "basic")
  }
  
  assertion_select <- select[select$type == "assertions", ]
  query$fields <- build_columns(select[select$type != "assertions", ])
  query$qa <- build_assertion_columns(assertion_select)
  if (mint_doi) {
    query$mintDoi <- "true"
  }
  
  if (getOption("galah_config")$atlas == "Australia") {
    query$emailNotify <- email_notify()
    query$sourceTypeId <- 2004
    query$reasonTypeId <- getOption("galah_config")$download_reason_id
  }

  # Get data
  tmp <- tempfile()
  url <- server_config("records_base_url")
  query <- c(query, email = user_email(), dwcHeaders = "true")
  download_resp <- wait_for_download(url, query)
  if(is.null(download_resp)){
    inform("Calling the API failed for `atlas_occurrences`")
    return(tibble())
  }
  download_path <- download_resp$download_path
  data_path <- ala_download(url = server_config("records_download_base_url"),
                       path = download_path,
                       cache_file = tmp, ext = ".zip")
  if(is.null(data_path)){
    inform("Calling the API failed for `atlas_occurrences`")
    return(tibble())
  }

  tryCatch(
    df <- read.csv(unz(data_path, "data.csv"), stringsAsFactors = FALSE),
    error = function(e) {
      bullets <- c(
        "There was a problem reading the occurrence data and it looks like no data were returned.",
        i = "This may be because no valid field names were provided.",
        i = "To check whether field names are valid, use `search_fields()`."
      )
      inform(bullets)
    }
  )

  # rename cols so they match requested cols
  names(df) <- rename_columns(names(df), type = "occurrence")

  # replace 'true' and 'false' with boolean
  if (nrow(assertion_select) > 0) {
    df <- fix_assertion_cols(df, assertion_select$name)
  }

  # add DOI as attribute
  df <- as_tibble(df)
  attr(df, "doi") <- get_doi(mint_doi, data_path)
  attr(df, "search_url") <- download_resp$search_url
  df
}


get_doi <- function(mint_doi, data_path) {
  doi <- NA
  if (as.logical(mint_doi)) {
    tryCatch(
      doi <- as.character(
        read.table(unz(data_path, "doi.txt"))$V1),
      warning = function(e) {
        e$message <- "No DOI was generated for this download. The DOI server may
        be down or, if this is a cached result, may not have been generated for
        the original download."
      })
  }
  return(doi)
}

wait_for_download <- function(url, query) {
  status <- atlas_GET(url, "occurrences/offline/download",
                    params = query, on_error = occ_error_handler)
  if(is.null(status)){return(NULL)}
  search_url <- status$searchUrl
  status_url <- parse_url(status$statusUrl)
  status <- atlas_GET(url, path = status_url$path)
  verbose <- getOption("galah_config")$verbose
  # create a progress bar
  if (verbose) {
    pb <- txtProgressBar(max = 1, style = 3)
  }
  
  while(status$status == "inQueue") {
    status <- atlas_GET(url, path = status_url$path)
  }

  while (tolower(status$status) == "running") {
    val <- (status$records / status$totalRecords)
    if (verbose) {
      setTxtProgressBar(pb, val)
    }
    status <- atlas_GET(url, path = status_url$path)
    Sys.sleep(2)
  }
  if (verbose) {
    setTxtProgressBar(pb, value = 1)
    close(pb)
  }
  
  resp <- list(download_path = parse_url(status$downloadUrl)$path,
               search_url = search_url)
  return(resp)
}

check_count <- function(count, error_call = caller_env()) {
  if (count == 0) {
    abort("This query does not match any records.", call = error_call)
  } else if (count > 50000000) {
    bullets <- c(
      "Your data request was too large.",
      i = "A maximum of 50 million records can be retrieved at once.",
      i = "Please narrow the query and try again."
    )
    abort(bullets, call = error_call)
  } else {
    if (getOption("galah_config")$verbose) {
      inform(glue("This query will return {count} records"))
      }
  }
}

doi_download <- function(doi, error_call = caller_env()) {
  # strip useful part of DOI
  doi_str <- str_split(doi, "ala.")[[1]][2]
  if (is.na(doi_str)) {
    bullets <- c(
      "DOI has not been generated by the ALA.",
      i = "DOIs created by the ALA have a prefix of 10.26197/ala."
    )
    abort(bullets, call = error_call)
  }

  path <- ala_download(server_config("doi_base_url"),
                       path = paste0("/doi/", doi_str, "/download"),
                       ext = ".zip", cache_file = tempfile(pattern = "data"))
  if(is.null(path)){
    NULL
  }else{
    record_file <- grep("^records", unzip(path, list=TRUE)$Name, 
                        ignore.case=TRUE, value=TRUE)
    df <- read.csv(unz(path, record_file), stringsAsFactors = FALSE)
    attr(df, "doi") <- doi
    return(df)
  }
}


email_notify <- function() {
  notify <- as.logical(getOption("galah_config")$send_email)
  if (is.na(notify)) {
    notify <- FALSE
  }
  # ala api requires lowercase
  ifelse(notify, "true", "false")
}

user_email <- function(error_call = rlang::caller_env()) {
  email <- getOption("galah_config")$email
  if (email == "") {
    email <- Sys.getenv("email")
  }
  if (email == "") {
    bullets <- c(
      "No user email was found.",
      i = glue("To download occurrence records you must provide a valid email ",
                     "address registered with the ALA using `galah_config(email = )`")
    )
    abort(bullets, call = error_call)
  }
  email
}

occ_error_handler <- function(code, error_call = rlang::caller_env()) {
  if (code == 403) {
    bullets <- c(
      "Status code 403 was returned.",
      i = glue("Is the email you provided to `galah_config()` registered with the ALA?")
    )
    inform(bullets)
  #   stop("Status code 403 was returned for this occurrence download request. This may be because
  # the email you provided is not registered with the ALA. Please check and try again.")
  }
  if (code == 504) {
    bullets <- c(
      "Status code 504 was returned.",
      i = "This usually means that the ALA system is down.",
      i = "If you continue to receive this error, please email support@ala.org.au"
    )
    inform(bullets)
  }
}
