#' Occurrence records
#'
#' The most common form of data stored by ALA are observations of
#' individual life forms, known as 'occurrences'. This function allows the
#' user to search for occurrence records that match their specific criteria,
#' and return them as a `data.frame` for analysis. Optionally,
#' the user can also request a DOI for a given download to facilitate citation
#' and re-use of specific data resources.
#'
#' @param taxa `data.frame`: generated by a call to
#' [search_taxa()]. This argument also accepts a vector of unique
#' species identifiers.
#' @param filter `data.frame`: generated by a call to
#' [galah_filter()]
#' @param geolocate `string`: generated by a call to
#' [galah_geolocate()]
#' @param select `data.frame`: generated by a call to
#' [galah_select()] 
#' @param mint_doi `logical`: by default no DOI will be generated. Set to
#' `TRUE` if you intend to use the data in a publication or similar
#' @param doi `string`: this argument enables retrieval of occurrence
#' records previously downloaded from the ALA, using the DOI generated by the
#' data.
#' @param refresh_cache `logical`: if set to `TRUE` and 
#' `galah_config(caching = TRUE)` then files cached from a previous query will 
#' be replaced by the current query
#' @details
#' Note that unless care is taken, some queries can be particularly large.
#' While most cases this will simply take a long time to process, if the number
#' of requested records is >50 million the call will not return any data. Users
#' can test whether this threshold will be reached by first calling
#' [atlas_counts()] using the same arguments that they intend to pass to
#' `atlas_occurrences`(). It may also be beneficial when requesting a large
#' number of records to show a progress bar by setting `verbose = TRUE` in
#' [galah_config()].
#' @return An object of class `tbl_df` and `data.frame` (aka a tibble) of 
#' occurrences, containing columns as specified by [galah_select()]. 
#' The `data.frame` object has the following attributes:
#' 
#' * a listing of the user-supplied arguments of the `data_request` 
#' (i.e., taxa, filter, geolocate, select)
#' * a `doi` of the data download
#' * the `search_url` of the query to ALA API
#' 
#' @section Examples:
#' ```{r, child = "man/rmd/setup.Rmd"}
#' ```
#' 
#' Search for occurrences matching a taxon identifier
#' 
#' ```{r, comment = "#>", collapse = TRUE, results = "hide", eval = FALSE}
#' galah_config(email = "your-email@email.com")
#' 
#' atlas_occurrences(taxa = search_taxa("Reptilia"))
#' ```
#'
#' Search for occurrences in a year range
#' 
#' ```{r, comment = "#>", collapse = TRUE, results = "hide", eval = FALSE}
#' atlas_occurrences(filter = galah_filter(year == seq(2010, 2020)))
#' ```
#'
#' Search for occurrences in a WKT-specified area
#' 
#' ```{r, comment = "#>", collapse = TRUE, results = "hide", eval = FALSE}
#' polygon <- "POLYGON((146.24960 -34.05930,146.37045 -34.05930,146.37045 -34.152549,146.24960 -34.15254,146.24960 -34.05930))"
#' occ <- atlas_occurrences(geolocate = galah_geolocate(polygon))
#' ```
#' 
#' You can also download occurrence records by piping with `%>%` or `|>`. Just 
#' begin your query with [galah_call()]
#' 
#' ```{r, comment = "#>", collapse = TRUE, results = "hide", eval = FALSE}
#' galah_call() %>%
#'   search_taxa("Reptilia") %>%
#'   galah_filter(year >= 2010) %>%
#'   galah_geolocate(polygon) %>%
#'   atlas_occurrences()
#' ```
#' 
#' @export
atlas_occurrences <- function(...) {
  UseMethod("atlas_occurrences")
}

#' @export
#' @rdname atlas_occurrences
atlas_occurrences.data_request <- function(request, ...) {
  current_call <- update_galah_call(request, ...) 
  custom_call <- current_call[
    names(current_call) %in% names(formals(atlas_occurrences.default))]
  do.call(atlas_occurrences.default, custom_call)
}

#' @export
#' @rdname atlas_occurrences
atlas_occurrences.default <- function(taxa = NULL, 
                              filter = NULL, 
                              geolocate = NULL,
                              select = galah_select(group = "basic"),
                              mint_doi = FALSE, 
                              doi, 
                              refresh_cache = FALSE) {

  verbose <- getOption("galah_config")$verbose
  assert_that(is.logical(mint_doi))
  
  if (!missing(doi) && !is.null(doi)) {
    # search for data using DOI
    result <- doi_download(doi)
    if(is.null(result)){
      bullets <- c(
        "Calling the API failed for `atlas_occurrences`.",
        i = "This might mean that the ALA system is down. Double check that your query is correct.",
        i = "If you continue to see this message, please email support@ala.org.au."
      )
      inform(bullets)
      return(tibble())
    }else{
      return(result)
    }
  }
  
  profile <- extract_profile(filter)
  query <- build_query(taxa, filter, geolocate, select, profile)
  
  # handle caching
  caching <- getOption("galah_config")$caching

  # Check record count
  if (getOption("galah_config")$run_checks) {
    count <- record_count(query)
    if (is.null(count)){
      bullets <- c(
        "Calling the API failed for `atlas_occurrences`.",
        i = "This might mean that the ALA system is down. Double check that your query is correct.",
        i = "If you continue to see this message, please email support@ala.org.au."
      )
      inform(bullets)
      return(tibble())
    }else{
      check_count(count) # aborts under selected circumstances
    }
  }
  
  # Add select to query
  assertion_select <- select[select$type == "assertions", ]
  query$fields <- build_columns(select[select$type != "assertions", ])
  query$qa <- build_assertion_columns(assertion_select)
  if (mint_doi) {
    query$mintDoi <- "true"
  }
  
  if (caching && !refresh_cache) {
    cache_file <- cache_filename("occurrences", unlist(query))
    if (file.exists(cache_file)) {
      return(read_cache_file(cache_file))
    }
  }
  
  if (getOption("galah_config")$atlas == "Australia") {
    query$emailNotify <- email_notify()
    query$sourceTypeId <- 2004
    query$reasonTypeId <- getOption("galah_config")$download_reason_id
  }

  # Get data
  tmp <- tempfile()
  url <- server_config("records_base_url")
  query <- c(query, email = user_email(), dwcHeaders = "true")
  download_resp <- wait_for_download(url, query)
  if(is.null(download_resp)){
    inform("Calling the API failed for `atlas_occurrences`")
    return(tibble())
  }
  download_path <- download_resp$download_path
  data_path <- ala_download(url = server_config("records_download_base_url"),
                       path = download_path,
                       cache_file = tmp, ext = ".zip")
  if(is.null(data_path)){
    inform("Calling the API failed for `atlas_occurrences`")
    return(tibble())
  }

  tryCatch(
    df <- read.csv(unz(data_path, "data.csv"), stringsAsFactors = FALSE),
    error = function(e) {
      bullets <- c(
        "There was a problem reading the occurrence data and it looks like no data were returned.",
        i = "This may be because no valid field names were provided.",
        i = "To check whether field names are valid, use `search_fields()`."
      )
      inform(bullets)
    }
  )

  # rename cols so they match requested cols
  names(df) <- rename_columns(names(df), type = "occurrence")

  # replace 'true' and 'false' with boolean
  if (nrow(assertion_select) > 0) {
    df <- fix_assertion_cols(df, assertion_select$name)
  }

  # add DOI as attribute
  attr(df, "doi") <- get_doi(mint_doi, data_path)
  attr(df, "search_url") <- download_resp$search_url
  query <- data_request(taxa, filter, geolocate, select)
  attr(df, "data_request") <- query
    
  if (caching) {
    write_cache_file(object = df, data_type = "occurrences",
                     cache_file = cache_file)
  }
  return(as_tibble(df))
}


get_doi <- function(mint_doi, data_path) {
  doi <- NA
  if (as.logical(mint_doi)) {
    tryCatch(
      doi <- as.character(
        read.table(unz(data_path, "doi.txt"))$V1),
      warning = function(e) {
        e$message <- "No DOI was generated for this download. The DOI server may
        be down or, if this is a cached result, may not have been generated for
        the original download."
      })
  }
  return(doi)
}

wait_for_download <- function(url, query) {
  status <- atlas_GET(url, "occurrences/offline/download",
                    params = query, on_error = occ_error_handler)
  if(is.null(status)){return(NULL)}
  search_url <- status$searchUrl
  status_url <- parse_url(status$statusUrl)
  status <- atlas_GET(url, path = status_url$path)
  verbose <- getOption("galah_config")$verbose
  # create a progress bar
  if (verbose) {
    pb <- txtProgressBar(max = 1, style = 3)
  }
  
  while(status$status == "inQueue") {
    status <- atlas_GET(url, path = status_url$path)
  }

  while (tolower(status$status) == "running") {
    val <- (status$records / status$totalRecords)
    if (verbose) {
      setTxtProgressBar(pb, val)
    }
    status <- atlas_GET(url, path = status_url$path)
    Sys.sleep(2)
  }
  if (verbose) {
    setTxtProgressBar(pb, value = 1)
    close(pb)
  }
  
  resp <- list(download_path = parse_url(status$downloadUrl)$path,
               search_url = search_url)
  return(resp)
}

check_count <- function(count, error_call = caller_env()) {
  if (count == 0) {
    rlang_abort("This query does not match any records.")
  } else if (count > 50000000) {
    bullets <- c(
      "Your data request was too large.",
      i = "A maximum of 50 million records can be retrieved at once.",
      i = "Please narrow the query and try again."
    )
    abort(bullets, call = error_call)
  } else {
    if (getOption("galah_config")$verbose) {
      inform(glue("This query will return {count} records"))
      }
  }
}

doi_download <- function(doi, error_call = caller_env()) {
  # strip useful part of DOI
  doi_str <- str_split(doi, "ala.")[[1]][2]
  if (is.na(doi_str)) {
    bullets <- c(
      "DOI has not been generated by the ALA.",
      i = "DOIs created by the ALA have a prefix of 10.26197/ala."
    )
    abort(bullets, call = error_call)
  }

  path <- ala_download(server_config("doi_base_url"),
                       path = paste0("/doi/", doi_str, "/download"),
                       ext = ".zip", cache_file = tempfile(pattern = "data"))
  if(is.null(path)){
    NULL
  }else{
    record_file <- grep("^records", unzip(path, list=TRUE)$Name, 
                        ignore.case=TRUE, value=TRUE)
    df <- read.csv(unz(path, record_file), stringsAsFactors = FALSE)
    attr(df, "doi") <- doi
    return(df)
  }
}


email_notify <- function() {
  notify <- as.logical(getOption("galah_config")$send_email)
  if (is.na(notify)) {
    notify <- FALSE
  }
  # ala api requires lowercase
  ifelse(notify, "true", "false")
}

user_email <- function(error_call = rlang::caller_env()) {
  email <- getOption("galah_config")$email
  if (email == "") {
    email <- Sys.getenv("email")
  }
  if (email == "") {
    bullets <- c(
      "No user email was found.",
      i = glue("To download occurrence records you must provide a valid email ",
                     "address registered with the ALA using `galah_config(email = )`")
    )
    abort(bullets, call = error_call)
  }
  email
}

occ_error_handler <- function(code, error_call = rlang::caller_env()) {
  if (code == 403) {
    bullets <- c(
      "Status code 403 was returned.",
      i = glue("Is the email you provided to `galah_config()` registered with the ALA?")
    )
    inform(bullets)
  #   stop("Status code 403 was returned for this occurrence download request. This may be because
  # the email you provided is not registered with the ALA. Please check and try again.")
  }
  if (code == 504) {
    bullets <- c(
      "Status code 504 was returned.",
      i = "This usually means that the ALA system is down.",
      i = "If you continue to receive this error, please email support@ala.org.au"
    )
    inform(bullets)
  }
}
