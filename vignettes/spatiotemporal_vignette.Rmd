---
title: "galah Temporal/Spatial Vignette"
format: html
editor: visual
---

Biodiversity queries to the ALA will almost always require some form of spatial or temporal filtering. It is important to know how these types of data are stored in the ALA, and how we can efficiently and correctly query them to obtain desired filters.

```{r, output = FALSE}
# Load important libraries
library(galah)
library(tidyverse)
library(knitr)
library(lubridate)
library(sf)
```

```{r, include = FALSE}
# set up galah session
galah_config(email = "callumwaite2000@gmail.com", verbose = FALSE)
```

```{r, eval = FALSE}
galah_config(email = "your_email_here", verbose = FALSE)
```

### Temporal filtering

The ALA database possesses numerous date and time fields that relate to each observation. Here we provide descriptions of each of these fields and how they are best used to obtain specific queries. Ultimately, there are two ways users can filter temporal queries:

-   filter using pre-existing/defined parameters, such as specific years or months

-   filter within a bespoke date and/or time range

All temporal filtering is conducted using `galah_filter()`. All temporal fields described below can be queried for exact matches (`==`), greater/less than (`>`, `<`) or greater/less than or equal to (`<=`, `>=`). Queries for multiple fields or multiple queries of the same field can be combined in the one `galah_filter()` call in order to obtain filters on time windows.

#### Year, Month and Day

The ALA contains in-built `year`, `month` and `day` fields for every record. These are queried as numeric fields (i.e. July = `7`) and can be used for quick data exploration and filtering. When the date limits of a desired query can be easily defined by year, month and/or day deliminations, these fields are most useful.

We can, for instance, use the `year` and `month` fields to group the 2022 amphibian records in the ALA by month (noting that months are labelled by a number).

```{r}
galah_call() |>
  galah_filter(class == "Amphibia", year == 2021) |>
  galah_group_by(month) |>
  atlas_counts()
```

It is also important to observe that the outputted `month` column is of type `character` even though the values are numeric. This is the case for each of the `year`, `month` and `day` fields. However, they can be queried as either numeric or character values within `galah_filter()`.

The other important fact about these fields when queried in `galah_filter()` is their independence - they cannot be used to query complex windows between two dates because the day and month filters are applied universally.

For instance, consider the native perennial Australian wildflower [*Chamaescilla corymbosa*](https://bie.ala.org.au/species/https://id.biodiversity.org.au/node/apni/2920316), whose known growth and flowering times are from August - October. We might be interested in the number of records for this species in the first week of spring (i.e. September) in each of the last 10 years. The following query does not provide all results between 1/9/2013 and the 7/9/2023. Rather, it will only return results that fall within all 3 windows at once.

```{r}
galah_call() |>
  galah_filter(species == "Chamaescilla corymbosa",
               year >= 2013, year <= 2023, month == 9, day >= 1, day <= 7) |>
  galah_group_by(year) |>
  atlas_counts() |>
  arrange(year)
```

#### Occurrence dates

For a more bespoke way to query exact dates of records, users can use the `eventDate` field. This field contains the exact date and time information of records and enables specific time windows to be queried easily. The only caveat to the use of this field is that it must be provided in a specific format to `galah_filter()` for the ALA query to work. However, the outputted `eventDate` value in the returned `data.frame` will be of date class `"POSIXct"`.

The required format of dates in `eventDate` is the [ISO 8601 International Date Standard](https://en.wikipedia.org/wiki/ISO_8601) format. This requires dates and times to be of the form "YYYY-MM-DDTHH:MM:SSZ". Note that the T in the middle should be the actual letter "T" to delimit the date and time components, while the "Z" officially denotes that the time should be queried as UTC (Greenwich Meridian) time. Timezones can be confusing at the best of times, however it is easiest to remember that all ALA records are recorded at the local time of their location, and all times are then treated as effectively being UTC times.

The upshot of this specific formatting is that, for instance, the time I am writing this paragraph, 4:26pm on the 2nd of August 2023, would be represented as `"2023-08-02T16:26:44Z"` in the ALA, even though officially my timezone is `"+0930"`.

Because `eventDate` specifies the time to seconds, it is recommended that greater or less than queries are used rather than exact matches. When used with `galah_filter()`, we can easily identify how many records of the humpback whale (*Megaptera novaeangliae*) have occurred since the species was [removed from the Australian threatened species list](http://www.environment.gov.au/biodiversity/threatened/species/pubs/38-listing-advice-26022022.pdf) on 26/02/2022.

```{r}
galah_call() |>
  galah_filter(species == "Megaptera novaeangliae", 
               eventDate >= "2022-02-26T00:00:00Z") |>
  atlas_counts()
```

It can be unintuitive to provide dates in this format. Luckily, it is very simple to convert standard R dates or {lubridate} dates into this format because they are already in the required "YYYY-MM-DD" form. If we took the above date (26/02/2022), it could be converted to this form using base R or lubridate as follows:

```{r}
humpback_date <- "26/02/2022"
# Base R
paste0(as.Date(humpback_date, format = "%d/%m/%Y"), "T00:00:00Z")
# lubridate
paste0(dmy(humpback_date), "T00:00:00Z")

```

#### Upload dates

The other important date field present in the ALA pertains to the date that the record was provided to the ALA. This field is called `firstLoadedDate` and is formatted in exactly the same manner as `eventDate`.

Different data providers provide batches of records to the ALA at different intervals. iNaturalist Australia provide weekly uploads of data, while eBird provides yearly uploads. `firstLoadedDate` can be especially useful for finding new records to the ALA that have been provided since you last checked. For instance, we can use it to see how many observations of Sulphur-Crested Cockatoos recorded in the first week of 2023 were actually loaded into the ALA by the following week:

```{r}
# Total records of Cactua galerita in Jan 1-7
galah_call() |>
  galah_filter(species == "Cacatua galerita",
               eventDate >= "2023-01-07T00:00:00Z", 
               eventDate < "2023-01-08T00:00:00Z") |>
  atlas_counts()
```

```{r}
# Records of Cactua galerita uploaded in Jan 1-14
galah_call() |>
  galah_filter(species == "Cacatua galerita",
               eventDate >= "2023-01-07T00:00:00Z", 
               eventDate < "2023-01-08T00:00:00Z",
               firstLoadedDate < "2023-01-15T00:00:00Z") |>
  atlas_counts()
```

Note that no lower bound is required for `firstLoadedDate` because `eventDate` imposes that by proxy (records can't be uploaded before they've occurred).

### Spatial filtering

Most records in the ALA contain location data in the form of two key fields: `decimalLatitude` and `decimalLongitude`. As expected, these fields are the decimal coordinates of each occurrence, with south and west values denoted by negatives. While there may be some uncertainty in these values (see field `coordinateUncertaintyInMeters`), they are generally very accurate.

While these are very important and useful fields, very rarely will we encounter situations that require queries directly calling `decimalLatitude` and `decimalLongitude`. Instead, the ALA and galah have a number of features that make spatial queries simpler.

#### Contextual and spatial layers

Often we want to filter results down to some commonly defined spatial regions, such as states, LGAs or IBRA/IMCRA regions. The ALA contains a large range (\>100) of contextual and spatial layers, in-built as searchable and queriable fields. They are denoted by names beginning with `"cl"`, followed by an identifying number that may be up to 6 digits long. These fields are each based on shapefiles, and contain the names of the regions in these layers that each record lies in.

We strongly recommend using `search_fields()` to check whether a contextual layer already exists in the ALA that matches what you require before proceeding with other methods of spatial filtering. These fields are all able to be queried with `galah_filter()`and so they are generally easier to use.

Suppose we are interested in querying records of the Red-Necked Avocet ([*Recurvirostra novaehollandiae*](https://bie.ala.org.au/species/https://biodiversity.org.au/afd/taxa/c69e7308-527a-429d-a80d-143bd20b5100)) in a particular protected wetlands, Lake Eyre wetlands in South Australia. We can search the ALA fields for wetlands.

```{r}
search_fields("wetlands")
```

Our search identifies that layer `cl901` seems to match what we are looking for. We can then either view all possible values in the field with `show_values()`, or search again for our particular field.

```{r}
search_fields("cl901") |> search_values("lake eyre")
```

We can filter all occurrences for exact matches with this value, `"Lake Eyre"`. Our galah query can be built as follows:

```{r}
galah_call() |>
  galah_identify("Recurvirostra novaehollandiae") |>
  galah_filter(cl901 == "Lake Eyre") |>
  atlas_occurrences() |>
  knitr::kable()
```

#### galah_geolocate()

Mostly, the shapefile or region you wish to query will not be pre-loaded as a contextual layer in the ALA. In this case, shapefiles can be introduced to the filtering process using the {sf} package and the `galah_geolocate()` function. Shapefiles can be provided as an `sf` object, whether that is by importing them with `sf::st_read()` or taking a `POLYGON` or `MULTIPOLYGON` character string and transforming them with `sf::st_as_sfc()`.

For instance, we might interested in species occurrences in King George Square, Brisbane. We can take the `MULTIPOLYGON` object for the square (as sourced from the [Brisbane City Council](https://www.data.brisbane.qld.gov.au/data/dataset/park-locations)) and transform it into `sfc` and then `sf` objects.

```{r}
king_george_sq <- "MULTIPOLYGON(((153.0243 -27.46886, 153.0242 -27.46896, 153.0236 -27.46837, 153.0239 -27.46814, 153.0239 -27.46813, 153.0242 -27.46789, 153.0244 -27.46805, 153.0245 -27.46821, 153.0246 -27.46828, 153.0247 -27.46835, 153.0248 -27.46848, 153.0246 -27.4686, 153.0246 -27.46862, 153.0245 -27.46871, 153.0243 -27.46886)))" |>
  sf::st_as_sfc() |> 
  sf::st_as_sf()
```

We can provide this `MULTIPOLYGON` in our filter as the argument of `galah_geolocate()` to assess which species have been recorded in King George Square.

```{r}
galah_call() |>
  galah_filter() |>
  galah_geolocate(king_george_sq) |>
  galah_select(decimalLatitude, decimalLongitude, eventDate, scientificName, vernacularName) |>
  atlas_occurrences() |> 
  knitr::kable()
```

There is a second argument of `galah_geolocate()` called `type`, which defaults to value `"polygon"`. By setting the `type` argument to `"bbox"`, the provided `POLYGON` or `MULTIPOLYGON` will be converted into the smallest bounding box (rectangle) that contains the `POLYGON`. In this case, records will be included that may not exactly lie inside the provided shape.

```{r}
galah_call() |>
  galah_filter() |>
  galah_geolocate(king_george_sq, type = "bbox") |>
  galah_select(decimalLatitude, decimalLongitude, eventDate, scientificName, vernacularName) |>
  atlas_occurrences() |> 
  knitr::kable()
```

#### Large shapefiles

The `type` argument with option `"bbox"` is provided because `sf` objects with \>500 vertices will not be accepted by the ALA. In the event you have a large shapefile, using `type = "bbox"` will at least enable an initial reduction of the data that is downloaded, before finer filtering to the actual shapefile will obtain the desired set of occurrences. Alternatively, one can also perform the `"bbox"` reduction before passing the shape to `galah_geolocate()` by using `sf::st_bbox()`.

A common situation for this to occur is when a shapefile with multiple shapes is provided, where we are interested in grouping our results by each shape. Here is a mock workflow using the shapefile of [all 2,184 Brisbane parks](https://www.data.brisbane.qld.gov.au/data/dataset/park-locations).

Let's say we are interested in which parks have the most occurrences of the Scaly-Breasted Lorikeet, [*Trichoglossus chlorolepidotus*](https://bie.ala.org.au//species/https://biodiversity.org.au/afd/taxa/ecaca7ec-da2e-4c6b-b190-14e7a1738884), in 2022. We can download the entire shapefile from the above link, and perform our filtering and summarising as follows:

```{r, include = FALSE}
# import actual data (WILL NEED TO SET YOUR OWN FILE PATH HERE)
load("brisbane_parks.rds")
# show fake import in below block
```

```{r, eval = FALSE}
brisbane_parks <- sf::st_read("path/to/Park___Locations.shp") |>
  sf::st_make_valid()
```

```{r}
# Convert shapefile to a bounding box
brisbane_parks_bbox <- brisbane_parks |> sf::st_bbox()

# Find all occurrences of Trichoglossus chlorolepidotus in the bounding box in 2022
lorikeet_brisbane <- galah_call() |>
  galah_filter(scientificName == "Trichoglossus chlorolepidotus", year == 2022) |>
  galah_geolocate(brisbane_parks_bbox, type = "bbox") |>
  atlas_occurrences()
```

```{r}
# Filter records down to only those in the shapefile polygons
lorikeet_brisbane |>
  # Create a point geometry based on the occurrence coordinates
  sf::st_as_sf(coords = c("decimalLongitude", "decimalLatitude"), crs = sf::st_crs(brisbane_parks), remove = FALSE) |>
  # identify which park each occurrence sits in with st_intersects()
  mutate(intersection = sf::st_intersects(geometry, brisbane_parks) |> as.integer(),
         park = ifelse(is.na(intersection), NA, brisbane_parks$PARK_NAME[intersection])) |>
  # Filter out occurrences that did not occur in a park
  filter(!is.na(park)) |>
  # Drop the geometry column
  sf::st_drop_geometry() |>
  # Summarise the top 10 parks for lorikeet sightings in 2022
  group_by(park) |>
  summarise(counts = n()) |>
  arrange(desc(counts)) |>
  head(10)
```

Some shapefiles cover large geographic areas with the caveat that even the bounding box doesn't restrict the number of records to a value that can be downloaded easily. In this case, we recommend more nuances and detailed methods that can be performed using looping techniques. One of our ALA Labs blog posts, [Hex maps for species occurrence data](https://labs.ala.org.au/posts/2021-04-14_hex-maps-for-species-occurrence-data/post.html), has been written detailing how to approach larger problems such as this.
